# Agent Server Configuration
AGENT_HOST=0.0.0.0
AGENT_PORT=8082
PYTHON_LOG_LEVEL=INFO

# LLM Provider: "ollama" or "vertex"
LLM_PROVIDER=ollama

# Ollama Configuration (when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Vertex AI Configuration (when LLM_PROVIDER=vertex)
# Option 1: Service account JSON file path
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Option 2: Service account JSON content (for containerized deployments)
# GOOGLE_APPLICATION_CREDENTIALS_CONTENT='{"type":"service_account",...}'

project_id: itpc-gcp-hcm-pe-eng-claude
region: us-east5
model: claude-sonnet-4-5@20250929

# OC Commands Analyzer MCP Server Configuration
MCP_SERVER_URL=http://localhost:5002/mcp/
MCP_SERVER_TRANSPORT=streamable_http

# Optional: Use SQLite for conversation checkpointing
USE_CHECKPOINTING=true
SQLITE_DB_PATH=./data/conversations.db
